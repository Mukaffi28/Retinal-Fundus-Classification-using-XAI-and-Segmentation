{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P-Y5MNfaOg_e",
    "outputId": "cc73812e-515a-401b-80b2-8c537638e4e4"
   },
   "outputs": [],
   "source": [
    "!pip install keras-unet-collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P-Y5MNfaOg_e",
    "outputId": "cc73812e-515a-401b-80b2-8c537638e4e4"
   },
   "outputs": [],
   "source": [
    "pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8U0Cuw9ASOxI"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras_unet_collection import models, losses\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "import cv2\n",
    "import random\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CdPuZP7PSZOM"
   },
   "source": [
    "# **Dataset Directory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YjDai0nKSO35"
   },
   "outputs": [],
   "source": [
    "# Define paths to our training, test, and validation Images\n",
    "train_image_directory = 'D:\\\\Data\\\\training\\\\Images'\n",
    "test_image_directory = 'D:\\\\Data\\\\test\\\\Original'\n",
    "validation_image_directory = 'D:\\\\Data\\\\val\\\\Original'\n",
    "\n",
    "# Define paths to our training, test, and validation Masks\n",
    "train_masks_directory = 'D:\\\\Data\\\\training\\\\Masks'\n",
    "test_masks_directory = 'D:\\\\Data\\\\test\\\\Ground truth'\n",
    "validation_masks_directory = 'D:\\\\Data\\\\val\\\\Ground truth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E_9uW7CKSb29"
   },
   "source": [
    "# **Train dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OFtJp3XMSO7R"
   },
   "outputs": [],
   "source": [
    "train_image_dataset = []\n",
    "train_mask_dataset = []\n",
    "SIZE = 224  # Assuming the desired size for the images is 64x64\n",
    "\n",
    "train_images = os.listdir(train_image_directory)\n",
    "for i, image_name in enumerate(train_images):\n",
    "    if image_name.split('.')[1] == 'png':\n",
    "        image = cv2.imread(os.path.join(train_image_directory, image_name))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "        image = Image.fromarray(image)\n",
    "        image = image.resize((SIZE, SIZE))\n",
    "        train_image_dataset.append(np.array(image))\n",
    "\n",
    "train_masks = os.listdir(train_masks_directory)\n",
    "for i, image_name in enumerate(train_masks):\n",
    "    if image_name.split('.')[1] == 'png':\n",
    "        image = cv2.imread(os.path.join(train_masks_directory, image_name), 0)\n",
    "        image = Image.fromarray(image)\n",
    "        image = image.resize((SIZE, SIZE))\n",
    "        train_mask_dataset.append(np.array(image))\n",
    "\n",
    "# Normalize images\n",
    "train_image_data = np.array(train_image_dataset) / 255.0\n",
    "# Rescale masks to 0 to 1\n",
    "train_mask_data = np.expand_dims(np.array(train_mask_dataset), 3) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z1PB7fuMSes3"
   },
   "source": [
    "# **Checking random images from train dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "id": "4Ankuzw6SVaa",
    "outputId": "65569bb0-bd21-4c5c-9dc4-103c5f02c28a"
   },
   "outputs": [],
   "source": [
    "# Display a random image along with its mask\n",
    "random_index = random.randint(0, len(train_image_data) - 1)\n",
    "random_image = train_image_data[random_index]\n",
    "random_mask = train_mask_data[random_index]\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "# Display the random image\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(random_image)\n",
    "plt.title('Random Image',fontdict={'family': 'serif', 'size': 12, 'weight': 'bold'})\n",
    "plt.axis('off')\n",
    "\n",
    "# Display the corresponding mask\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(random_mask[:, :, 0], cmap='gray')  # Assuming the mask is a single-channel image\n",
    "plt.title('Corresponding Mask',fontdict={'family': 'serif', 'size': 12, 'weight': 'bold'})\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VWs7G_FvSiof"
   },
   "source": [
    "# **Test Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LW0kUBPHSVda"
   },
   "outputs": [],
   "source": [
    "test_image_dataset = []\n",
    "test_mask_dataset = []\n",
    "SIZE = 224  # Assuming the desired size for the images is 64x64\n",
    "\n",
    "test_images = os.listdir(test_image_directory)\n",
    "for i, image_name in enumerate(test_images):\n",
    "    if image_name.split('.')[1] == 'png':\n",
    "        image = cv2.imread(os.path.join(test_image_directory, image_name))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "        image = Image.fromarray(image)\n",
    "        image = image.resize((SIZE, SIZE))\n",
    "        test_image_dataset.append(np.array(image))\n",
    "\n",
    "test_masks = os.listdir(test_masks_directory)\n",
    "for i, image_name in enumerate(test_masks):\n",
    "    if image_name.split('.')[1] == 'png':\n",
    "        image = cv2.imread(os.path.join(test_masks_directory, image_name), 0)\n",
    "        image = Image.fromarray(image)\n",
    "        image = image.resize((SIZE, SIZE))\n",
    "        test_mask_dataset.append(np.array(image))\n",
    "\n",
    "# Normalize images\n",
    "test_image_data = np.array(test_image_dataset) / 255.0\n",
    "# Rescale masks to 0 to 1\n",
    "test_mask_data = np.expand_dims(np.array(test_mask_dataset), 3) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wii1LrdcSmJh"
   },
   "source": [
    "# **Checking random images from test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "id": "MCkHQ-HhSVg6",
    "outputId": "3d9148ed-7598-46cb-9c79-9a5369f46c54"
   },
   "outputs": [],
   "source": [
    "# Display a random image along with its mask\n",
    "random_index = random.randint(0, len(test_image_data) - 1)\n",
    "random_image = test_image_data[random_index]\n",
    "random_mask = test_mask_data[random_index]\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "# Display the random image\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(random_image)\n",
    "plt.title('Random Image',fontdict={'family': 'serif', 'size': 12, 'weight': 'bold'})\n",
    "plt.axis('off')\n",
    "\n",
    "# Display the corresponding mask\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(random_mask[:, :, 0], cmap='gray')  # Assuming the mask is a single-channel image\n",
    "plt.title('Corresponding Mask',fontdict={'family': 'serif', 'size': 12, 'weight': 'bold'})\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zHFP8siwSrFb"
   },
   "source": [
    "# **Validation Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_-C-gZ_QSnkC"
   },
   "outputs": [],
   "source": [
    "validation_image_dataset = []\n",
    "validation_mask_dataset = []\n",
    "SIZE = 224  # Assuming the desired size for the images is 64x64\n",
    "\n",
    "validation_images = os.listdir(test_image_directory)\n",
    "for i, image_name in enumerate(validation_images):\n",
    "    if image_name.split('.')[1] == 'png':\n",
    "        image = cv2.imread(os.path.join(test_image_directory, image_name))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "        image = Image.fromarray(image)\n",
    "        image = image.resize((SIZE, SIZE))\n",
    "        validation_image_dataset.append(np.array(image))\n",
    "\n",
    "validation_masks = os.listdir(test_masks_directory)\n",
    "for i, image_name in enumerate(test_masks):\n",
    "    if image_name.split('.')[1] == 'png':\n",
    "        image = cv2.imread(os.path.join(test_masks_directory, image_name), 0)\n",
    "        image = Image.fromarray(image)\n",
    "        image = image.resize((SIZE, SIZE))\n",
    "        validation_mask_dataset.append(np.array(image))\n",
    "\n",
    "# Normalize images\n",
    "validation_image_data = np.array(validation_image_dataset) / 255.0\n",
    "# Rescale masks to 0 to 1\n",
    "validation_mask_data = np.expand_dims(np.array(validation_mask_dataset), 3) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4mjUfffSvdU"
   },
   "source": [
    "# **Checking random images from validation dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "id": "iO0UXtEJSnpK",
    "outputId": "b74b8c49-909a-4899-e54f-5163a49e72b6"
   },
   "outputs": [],
   "source": [
    "# Display a random image along with its mask\n",
    "random_index = random.randint(0, len(validation_image_data) - 1)\n",
    "random_image = validation_image_data[random_index]\n",
    "random_mask = validation_mask_data[random_index]\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "# Display the random image\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(random_image)\n",
    "plt.title('Random Image',fontdict={'family': 'serif', 'size': 12, 'weight': 'bold'})\n",
    "plt.axis('off')\n",
    "\n",
    "# Display the corresponding mask\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(random_mask[:, :, 0], cmap='gray')  # Assuming the mask is a single-channel image\n",
    "plt.title('Corresponding Mask',fontdict={'family': 'serif', 'size': 12, 'weight': 'bold'})\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oD8ckBIbS0lm"
   },
   "source": [
    "# **Segmnetation Model: Attention_UNet**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Define the checkpoint filepath\n",
    "checkpoint_filepath = 'D:\\\\Data\\\\UNets\\\\Drive_AttUNet_Resnet101V2_best_model_checkpoint.hdf5'\n",
    "\n",
    "# Create a ModelCheckpoint callback\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    checkpoint_filepath,\n",
    "    monitor='val_mean_iou',  # You can change this to 'val_accuracy' or any other metric\n",
    "    save_best_only=True,  # Save only the best model\n",
    "    mode='max',  # 'min' for loss, 'max' for accuracy, 'auto' to infer automatically\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Backbone:**\n",
    "* **ResNet101V2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DbXIeoX0Sw2m",
    "outputId": "ea9c0a32-7b8f-4232-9b26-ead2919a3efb"
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH  = 224\n",
    "IMG_CHANNELS = 3\n",
    "num_labels = 1  #Binary\n",
    "input_shape = (IMG_HEIGHT,IMG_WIDTH,IMG_CHANNELS)\n",
    "batch_size = 1\n",
    "\n",
    "model_att_unet = models.att_unet_2d((224, 224, 3), filter_num=[64, 128, 256, 512, 1024],\n",
    "                           n_labels=num_labels,\n",
    "                           stack_num_down=2, stack_num_up=2,\n",
    "                           activation='ReLU',\n",
    "                           atten_activation='ReLU', attention='add',\n",
    "                           output_activation='Sigmoid',\n",
    "                           batch_norm=True, pool=False, unpool=False,\n",
    "                           backbone='ResNet101V2', weights='imagenet',\n",
    "                           freeze_backbone=True, freeze_batch_norm=True,\n",
    "                           name='attunet')\n",
    "\n",
    "\n",
    "model_att_unet.compile(loss='binary_crossentropy', optimizer=Adam(lr = 1e-3),\n",
    "              metrics=['accuracy', losses.dice_coef])\n",
    "\n",
    "print(model_att_unet.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GrAe4R5aTB9M"
   },
   "source": [
    "# **Training starts here...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def mean_iou(y_true, y_pred):\n",
    "    intersection = K.sum(K.abs(y_true * K.round(y_pred)))\n",
    "    union = K.sum(y_true) + K.sum(K.round(y_pred)) - intersection\n",
    "    iou = intersection / (union + K.epsilon())\n",
    "    return iou\n",
    "\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    intersection = K.sum(y_true * y_pred)\n",
    "    union = K.sum(y_true) + K.sum(y_pred)\n",
    "    dice = (2. * intersection) / (union + K.epsilon())\n",
    "    return dice\n",
    "\n",
    "model_att_unet.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=1e-3),metrics=[mean_iou, dice_coefficient])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FV9D4HJhqnA9",
    "outputId": "0aa6e829-7a91-4b97-ff70-75a8874b7e2f"
   },
   "outputs": [],
   "source": [
    "start1 = datetime.now()\n",
    "\n",
    "Unet_history = model_att_unet.fit(train_image_data, train_mask_data,\n",
    "                    verbose=1,\n",
    "                    batch_size = 8,\n",
    "                    validation_data=(test_image_data, test_mask_data),\n",
    "                    shuffle=False,\n",
    "                    epochs=50,\n",
    "                    callbacks=[model_checkpoint])\n",
    "\n",
    "stop1 = datetime.now()\n",
    "#Execution time of the model\n",
    "execution_time_Unet = stop1-start1\n",
    "print(\"UNet execution time is: \", execution_time_Unet)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CvFFq2WvTGru"
   },
   "source": [
    "# **Saved the trained model for the 1st time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7g9z3cxUTDJl",
    "outputId": "cbd310c2-2130-4787-ceca-2b56c1cbcd69"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "# Assuming 'model_Unet' is our trained UNet model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MzhESfx6TO1q"
   },
   "source": [
    "# **Load the trained model for training again**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "# Load the model and provide the custom metric functions to custom_objects\n",
    "best_model = load_model(checkpoint_filepath, \n",
    "                        custom_objects={'mean_iou': mean_iou, 'dice_coefficient': dice_coefficient})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=1e-3),metrics=[mean_iou, dice_coefficient])\n",
    "# Continue training from where it left off\n",
    "start2 = datetime.now()\n",
    "\n",
    "Unet_history_continued = best_model.fit(\n",
    "    train_image_data,  # Additional training images if needed\n",
    "    train_mask_data,   # Additional training masks if needed\n",
    "    verbose=1,\n",
    "    initial_epoch=80,\n",
    "    batch_size=8,\n",
    "    validation_data=(test_image_data, test_mask_data),#(validation_image_data, validation_mask_data),\n",
    "    shuffle=True,\n",
    "    epochs=580,  # Set the number of additional epochs or as needed\n",
    "    callbacks=[model_checkpoint],  # Continue using the ModelCheckpoint callback\n",
    ")\n",
    "\n",
    "stop2 = datetime.now()\n",
    "execution_time_Unet_continued = stop2 - start2\n",
    "print(\"Continued UNet execution time is: \", execution_time_Unet_continued)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qAWG0wELTDN9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ltif8vlNTUuU"
   },
   "source": [
    "# **Plotting Accuracy vs Loss Graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 540
    },
    "id": "6pNTRyaNTQZT",
    "outputId": "eaeb7913-09fd-4599-e695-fe0c0d201b81"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "import numpy as np\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "#Check history plots, one model at a time\n",
    "history = Unet_history_continued\n",
    "# Plot Loss\n",
    "train_loss, = plt.plot(Unet_history_continued.history['loss'], label='Train Loss', color='blue')\n",
    "val_loss, = plt.plot(Unet_history_continued.history['val_loss'], label='Validation Loss', color='orange')\n",
    "train_accuracy, = plt.plot(Unet_history_continued.history['dice_coefficient'], label='Train dice_coefficient',  color='green')\n",
    "val_accuracy, = plt.plot(Unet_history_continued.history['val_dice_coefficient'], label='Validation dice_coefficient', color='red')\n",
    "\n",
    "\n",
    "# Add a title with specified font properties\n",
    "plt.title('Model Performance during Training', fontdict={'family': 'Serif', 'weight': 'bold', 'size': 12},pad=10)\n",
    "# Set x-axis label with specified font properties\n",
    "plt.xlabel('No. of Epochs', fontdict={'family': 'Serif', 'weight': 'bold', 'size': 12})\n",
    "\n",
    "# Set x-axis ticks font properties\n",
    "plt.xticks(np.linspace(0, len(history.history['loss']), num=6), fontname='Serif', weight='bold')\n",
    "\n",
    "# Set y-axis ticks font properties\n",
    "plt.yticks(np.linspace(0.2, 1, num=5), fontname='Serif', weight='bold')\n",
    "\n",
    "# Set the x-axis and y-axis limits\n",
    "plt.xlim(0, len(history.history['loss']))\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "# Define custom legend lines with desired line properties\n",
    "legend_lines = [\n",
    "    Line2D([0], [0], color='blue', lw=3),          # Train Loss\n",
    "    Line2D([0], [0], color='orange', lw=3),       # Validation Loss\n",
    "    Line2D([0], [0], color='green', lw=3),        # Train Accuracy\n",
    "    Line2D([0], [0], color='red', lw=3)           # Validation Accuracy\n",
    "]\n",
    "\n",
    "# Place legend outside the graph by adjusting bbox_to_anchor and specifying it to be outside the axes\n",
    "plt.legend(legend_lines, ['Train Loss', 'Validation Loss', 'Train dice_coefficient', 'Validation dice_coefficient'],\n",
    "           loc='lower center', bbox_to_anchor=(0.5, 1.1), ncol=5,\n",
    "           prop={'family': 'Serif', 'weight': 'bold', 'size': 8}, frameon=False,\n",
    "           handler_map={Line2D: HandlerLine2D(numpoints=5)})\n",
    "\n",
    "# Adjust padding between x-axis label and x-axis ticks\n",
    "plt.gca().xaxis.labelpad = 10  # Change the value as needed to adjust the space\n",
    "\n",
    "\n",
    "# Display gridlines for better readability\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M4fEOcJkTbCW"
   },
   "source": [
    "# **Checking prediction on images from Test Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "# Load the model and provide the custom metric functions to custom_objects\n",
    "best_model = load_model(checkpoint_filepath, \n",
    "                        custom_objects={'mean_iou': mean_iou, 'dice_coefficient': dice_coefficient})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 354
    },
    "id": "7SSeiMkRTQcj",
    "outputId": "3b23283a-615e-47a1-94f3-33dab077003b"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = best_model\n",
    "\n",
    "test_img_number =5 # Change the index number here...\n",
    "\n",
    "test_img = test_image_data[test_img_number]\n",
    "ground_truth = test_mask_data[test_img_number]\n",
    "test_img_input = np.expand_dims(test_img, 0)\n",
    "prediction = (model.predict(test_img_input)[0, :, :, 0] > 0.55).astype(np.uint8)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "axs[0].imshow(test_img)\n",
    "axs[0].set_title('Original', fontdict={'family': 'serif', 'size': 12, 'weight': 'bold'} ,pad=10)\n",
    "axs[0].axis('off')\n",
    "\n",
    "axs[1].imshow(ground_truth[:, :, 0], cmap='gray')\n",
    "axs[1].set_title('Ground Truth', fontdict={'family': 'serif', 'size': 12, 'weight': 'bold'} ,pad=10)\n",
    "axs[1].axis('off')\n",
    "\n",
    "prediction_visual = axs[2].imshow(prediction, cmap='gray')\n",
    "axs[2].set_title('Predicted Mask', fontdict={'family': 'serif', 'size': 12, 'weight': 'bold'} ,pad=10)\n",
    "axs[2].axis('off')\n",
    "# Save the plotted images\n",
    "plt.savefig('D:\\\\Data\\\\Resnet101\\\\Drive_att_Resnet101V2_prediction_images5.pdf')  # Modify the file name as needed\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SBf2eSExTgs4"
   },
   "source": [
    "# **Segmentation Evaluation Metrics**\n",
    "* Intersection over Union (IoU)\n",
    "* Dice Coefficient\n",
    "* Pixel Accuracy\n",
    "* Surface Dice Overlap\n",
    "* Modified Hausdorff Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def m_iou(y_true, y_pred):\n",
    "    y_true_float = K.cast(y_true, dtype=tf.float32)\n",
    "    y_pred_float = K.cast(K.round(y_pred), dtype=tf.float32)\n",
    "\n",
    "    intersection = K.sum(K.abs(y_true_float * y_pred_float))\n",
    "    union = K.sum(y_true_float) + K.sum(y_pred_float) - intersection\n",
    "    iou = intersection / (union + K.epsilon())\n",
    "    \n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coeff(y_true, y_pred):\n",
    "    y_true_float = K.cast(y_true, dtype=tf.float32)\n",
    "    y_pred_float = K.cast(K.round(y_pred), dtype=tf.float32)\n",
    "    \n",
    "    intersection = K.sum(y_true_float * y_pred_float)\n",
    "    union = K.sum(y_true_float) + K.sum(y_pred_float)\n",
    "    dice = (2. * intersection) / (union + K.epsilon())\n",
    "    return dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from skimage.measure import label, regionprops\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "\n",
    "# Initialize lists to store evaluation metrics for each image\n",
    "IoU_values = []\n",
    "dice_coefficient_values = []\n",
    "pixel_accuracy_values = []\n",
    "modified_hausdorff_distance_values = []\n",
    "\n",
    "n_classes = 2  # Assuming binary segmentation\n",
    "\n",
    "for img in range(0, test_image_data.shape[0]):\n",
    "    temp_img = test_image_data[img]\n",
    "    ground_truth = test_mask_data[img]\n",
    "    temp_img_input = np.expand_dims(temp_img, 0)\n",
    "    prediction = (best_model.predict(temp_img_input)[0, :, :, 0] > 0.5).astype(np.uint8)\n",
    "\n",
    "    y_true= ground_truth[:, :, 0]\n",
    "    y_pred=prediction\n",
    "    y_true_float = K.cast(y_true, dtype=tf.float32)\n",
    "    y_pred_float = K.cast(K.round(y_pred), dtype=tf.float32)\n",
    "    # Intersection over Union (IoU)\n",
    "    intersection = K.sum(y_true_float * y_pred_float)\n",
    "    \n",
    "    iou = m_iou(ground_truth[:, :, 0], prediction)\n",
    "    IoU_values.append(iou)\n",
    "\n",
    "    # # Dice Coefficient\n",
    "    dice = dice_coeff(ground_truth[:, :, 0], prediction)\n",
    "    dice_coefficient_values.append(dice)\n",
    "    # Dice Coefficient\n",
    "    #dice = (2 * np.sum(intersection)) / (np.sum(ground_truth[:, :, 0]) + np.sum(prediction))\n",
    "    dice_coefficient_values.append(dice)\n",
    "    \n",
    "    # Pixel Accuracy\n",
    "    pixel_accuracy = np.sum(intersection) / np.sum(ground_truth[:, :, 0])\n",
    "    pixel_accuracy_values.append(pixel_accuracy)\n",
    "    \n",
    "\n",
    "    # Modified Hausdorff Distance\n",
    "    hausdorff_distance = directed_hausdorff(ground_truth[:, :, 0], prediction)[0]\n",
    "    modified_hausdorff_distance_values.append(hausdorff_distance)\n",
    "\n",
    "# Calculate mean values for all metrics\n",
    "mean_IoU = np.mean(IoU_values)\n",
    "mean_dice_coefficient = np.mean(dice_coefficient_values)\n",
    "mean_pixel_accuracy = np.mean(pixel_accuracy_values)\n",
    "mean_modified_hausdorff_distance = np.mean(modified_hausdorff_distance_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XTLwlfPZTQgj",
    "outputId": "58d3540c-4ec7-4f19-9b27-bb0530e2b395"
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import precision_recall_fscore_support\n",
    "# from skimage.measure import label, regionprops\n",
    "# from scipy.spatial.distance import directed_hausdorff\n",
    "\n",
    "# # Initialize lists to store evaluation metrics for each image\n",
    "# IoU_values = []\n",
    "# dice_coefficient_values = []\n",
    "# pixel_accuracy_values = []\n",
    "\n",
    "# modified_hausdorff_distance_values = []\n",
    "\n",
    "# n_classes = 2  # Assuming binary segmentation\n",
    "\n",
    "# for img in range(0, test_image_data.shape[0]):\n",
    "#     temp_img = test_image_data[img]\n",
    "#     ground_truth = test_mask_data[img]\n",
    "#     temp_img_input = np.expand_dims(temp_img, 0)\n",
    "#     prediction = (best_model.predict(temp_img_input)[0, :, :, 0] > 0.6).astype(np.float32)\n",
    "\n",
    "#     # # Intersection over Union (IoU)\n",
    "#     # intersection = np.logical_and(ground_truth[:, :, 0], prediction)\n",
    "#     # union = np.logical_or(ground_truth[:, :, 0], prediction)\n",
    "#     # iou = np.sum(intersection) / np.sum(union)\n",
    "#     iou =mean_iou(ground_truth[:, :, 0], prediction)\n",
    "#     IoU_values.append(iou)\n",
    "\n",
    "#     # Dice Coefficient\n",
    "#     dice = (2 * np.sum(intersection)) / (np.sum(ground_truth[:, :, 0]) + np.sum(prediction))\n",
    "#     dice_coefficient_values.append(dice)\n",
    "\n",
    "#     # Pixel Accuracy\n",
    "#     pixel_accuracy = np.sum(intersection) / np.sum(ground_truth[:, :, 0])\n",
    "#     pixel_accuracy_values.append(pixel_accuracy)\n",
    "#     dpixel_accuracy\n",
    "\n",
    "#     # Modified Hausdorff Distance\n",
    "#     hausdorff_distance = directed_hausdorff(ground_truth[:, :, 0], prediction)[0]\n",
    "#     modified_hausdorff_distance_values.append(hausdorff_distance)\n",
    "\n",
    "# # Calculate mean values for all metrics\n",
    "# mean_IoU = np.mean(IoU_values)\n",
    "# mean_dice_coefficient = np.mean(dice_coefficient_values)\n",
    "# mean_pixel_accuracy = np.mean(pixel_accuracy_values)\n",
    "# mean_modified_hausdorff_distance = np.mean(modified_hausdorff_distance_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dice_coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c =best_model.evaluate(test_image_data, test_mask_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c =best_model.evaluate(validation_image_data, validation_mask_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model.compile(loss='binary_crossentropy', optimizer=Adam(lr = 1e-3),\n",
    "#               metrics=['accuracy', losses.dice_coef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a,b,c =best_model.evaluate(test_image_data, test_mask_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "grEP69ePTht6",
    "outputId": "4f29c77b-cbce-4c16-cc92-3ce890b63732"
   },
   "outputs": [],
   "source": [
    "surface_dice_overlap_values = []\n",
    "\n",
    "n_classes = 2  # Assuming binary segmentation\n",
    "\n",
    "for img in range(0, test_image_data.shape[0]):\n",
    "    temp_img = test_image_data[img]\n",
    "    ground_truth = test_mask_data[img]\n",
    "    temp_img_input = np.expand_dims(temp_img, 0)\n",
    "    prediction = (best_model.predict(temp_img_input)[0, :, :, 0] > 0.6).astype(np.uint8)\n",
    "\n",
    "    # Surface Dice Overlap (Assuming binary images)\n",
    "    labeled_true = label(ground_truth[:, :, 0])\n",
    "    labeled_pred = label(prediction)\n",
    "    props_true = regionprops(labeled_true)\n",
    "    props_pred = regionprops(labeled_pred)\n",
    "\n",
    "    # Calculate Surface Dice Overlap for each pair of regions\n",
    "    dice_overlap_sum = 0\n",
    "    pairs_count = 0\n",
    "\n",
    "    for p in props_true:\n",
    "        for q in props_pred:\n",
    "            intersection = np.logical_and(labeled_true == p.label, labeled_pred == q.label)\n",
    "            if np.sum(intersection) > 0:\n",
    "                dice_overlap = 2 * np.sum(intersection) / (np.sum(labeled_true == p.label) + np.sum(labeled_pred == q.label))\n",
    "                dice_overlap_sum += dice_overlap\n",
    "                pairs_count += 1\n",
    "\n",
    "    surface_dice_overlap = dice_overlap_sum / pairs_count if pairs_count > 0 else 0\n",
    "    surface_dice_overlap_values.append(surface_dice_overlap)\n",
    "\n",
    "# Calculate mean value for surface dice overlap\n",
    "mean_surface_dice_overlap = np.mean(surface_dice_overlap_values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ETmi9BXmTmzL"
   },
   "source": [
    "# **Print mean values of Evaluation metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iwtguPrKThxM",
    "outputId": "fde5d3e6-8f86-40c0-95de-6bb76283213c"
   },
   "outputs": [],
   "source": [
    "# Print mean values\n",
    "print(\"Mean Intersection over Union (IoU):\", mean_IoU)\n",
    "print(\"Mean Dice Coefficient:\", mean_dice_coefficient)\n",
    "print(\"Mean Pixel Accuracy:\", mean_pixel_accuracy)\n",
    "print(\"Mean Modified Hausdorff Distance:\", mean_modified_hausdorff_distance)\n",
    "print(\"Mean Surface Dice Overlap:\", mean_surface_dice_overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Intersection over Union (IoU): 0.671802\n",
    "# Mean Dice Coefficient: 0.80241597\n",
    "# Mean Pixel Accuracy: 0.8115557339888061\n",
    "# Mean Modified Hausdorff Distance: 3.55132823836571\n",
    "# Mean Surface Dice Overlap: 0.02352653352875096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#121\n",
    "# Mean Intersection over Union (IoU): 0.67177504\n",
    "# Mean Dice Coefficient: 0.8030064\n",
    "# Mean Pixel Accuracy: 0.82494004844431\n",
    "# Mean Modified Hausdorff Distance: 3.447182809658836\n",
    "# Mean Surface Dice Overlap: 0.024977825861787435"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Intersection over Union (IoU): 0.68729764\n",
    "# Mean Dice Coefficient: 0.81435645\n",
    "# Mean Pixel Accuracy: 0.7866487424188215\n",
    "# Mean Modified Hausdorff Distance: 3.2814635012733757\n",
    "# Mean Surface Dice Overlap: 0.05919223477324746"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#50V2\n",
    "# Mean Intersection over Union (IoU): 0.71756387\n",
    "# Mean Dice Coefficient: 0.8353664\n",
    "# Mean Pixel Accuracy: 0.8512841755926897\n",
    "# Mean Modified Hausdorff Distance: 2.891307028937002\n",
    "# Mean Surface Dice Overlap: 0.020092759823854323"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#101V2\n",
    "# Mean Intersection over Union (IoU): 0.7221947\n",
    "# Mean Dice Coefficient: 0.8385104\n",
    "# Mean Pixel Accuracy: 0.8507688760998224\n",
    "# Mean Modified Hausdorff Distance: 2.800991135902577\n",
    "# Mean Surface Dice Overlap: 0.022378179005487955"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#152V2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
