{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q7r2o2tFgzsO"
   },
   "source": [
    "# **Importing necessary libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ep55mps6EiCB"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.applications.densenet import DenseNet121, DenseNet169, DenseNet201\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, log_loss, jaccard_score\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import zipfile\n",
    "from PIL import Image\n",
    "from shutil import copyfile  # Import the copyfile function\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FmqVzd9RjAN_"
   },
   "source": [
    "# **Unzipping Zip files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "id": "uryV3a6tiJ6R",
    "outputId": "597d40a9-cfa2-406f-badb-cb98e1f79440"
   },
   "outputs": [],
   "source": [
    "# Function to save and display Faster ScoreCAM\n",
    "def save_and_display_faster_scorecam(img_path, heatmap, alpha=0.7):\n",
    "    # Load the original image\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (224, 224))  # Resize image to match model input size\n",
    "\n",
    "    # Resize heatmap to match the image dimensions\n",
    "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "\n",
    "    # Rescale heatmap to a range 0-255\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "\n",
    "    # Apply heatmap on the original image\n",
    "    superimposed_img = cv2.addWeighted(heatmap, alpha, img, 1 - alpha, 0)\n",
    "\n",
    "    # Display the GradCAM visualization using Matplotlib\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    plt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Original', fontdict={'family': 'Serif', 'weight': 'bold', 'size': 12})\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    # Save the figure\n",
    "    plt.savefig('D:\\Data\\\\fundus_graphs\\\\DenseNet__faster_scorecam.pdf')  # Save as pdf format\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmQUVaqcRU1d"
   },
   "source": [
    "# **Checking GPU availability**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LQl7706tE4-k",
    "outputId": "a4331f4d-208c-4955-e3c1-81831013fa6d"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check if GPU is available\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print('GPU is available')\n",
    "    # Additional GPU configuration (optional)\n",
    "    physical_devices = tf.config.list_physical_devices('GPU')\n",
    "    try:\n",
    "        # For TensorFlow 2.x\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except:\n",
    "        # For TensorFlow 1.x\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "else:\n",
    "    print('GPU is not available')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s8xaZJuoRZSn"
   },
   "source": [
    "# **Dataset Path**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T0vWY27VGBg0"
   },
   "outputs": [],
   "source": [
    "# Define paths to our training, test, and validation data\n",
    "train_path = 'D:\\\\Data\\\\fundus\\\\train\\\\Original\\\\' \n",
    "test_path = 'D:\\\\Data\\\\fundus\\\\test\\\\Original\\\\'\n",
    "validation_path = 'D:\\\\Data\\\\fundus\\\\validation\\\\Original\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JbKPAzQkRbk4"
   },
   "source": [
    "# **Dataset Manipulation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GTgOT9jhEpG1"
   },
   "outputs": [],
   "source": [
    "# Function to load images and labels in batches using PIL\n",
    "def load_images_and_labels(folder_path):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            label = filename.split('_')[-1][0]  # Extract label (A, D, G, N) from filename\n",
    "\n",
    "            img = Image.open(image_path).convert('RGB')  # Load image using PIL and convert to RGB format\n",
    "            img = img.resize((224, 224))  # Resize image to (224, 224)\n",
    "            img_array = np.array(img)  # Convert PIL image to NumPy array\n",
    "            images.append(img_array)\n",
    "            labels.append(label)\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "\n",
    "\n",
    "# Load images and labels\n",
    "train_images, train_labels = load_images_and_labels(train_path)\n",
    "test_images, test_labels = load_images_and_labels(test_path)\n",
    "validation_images, validation_labels = load_images_and_labels(validation_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jZQxWKPAGkzR"
   },
   "outputs": [],
   "source": [
    "# Define a mapping dictionary from string labels to numeric labels\n",
    "label_map = {'A': 0, 'D': 1, 'G': 2, 'N': 3}\n",
    "\n",
    "# Convert string labels to numeric labels\n",
    "train_numeric_labels = np.array([label_map[label] for label in train_labels])\n",
    "test_numeric_labels = np.array([label_map[label] for label in test_labels])\n",
    "validation_numeric_labels = np.array([label_map[label] for label in validation_labels])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mqBoRACM3NBI"
   },
   "source": [
    "**Change the variations of DenseNet to check the results**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2B62CEtqRejp"
   },
   "source": [
    "# **Pre-trained CNN for Feature Extraction**\n",
    "* **DenseNet121**\n",
    "* **DenseNet169**\n",
    "* **DenseNet201**\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s2rZtl7rKTZr"
   },
   "outputs": [],
   "source": [
    "# Define model architecture\n",
    "def create_model(summary=True):\n",
    "    new_input = Input(shape=(224, 224, 3))\n",
    "    model = DenseNet121(weights='imagenet', include_top=False, input_tensor=new_input)\n",
    "    flat1 = Flatten()(model.layers[-1].output)\n",
    "    output = Dense(4, activation='softmax')(flat1)  # Assuming 4 classes\n",
    "    model = tf.keras.Model(inputs=model.inputs, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    if summary:\n",
    "        print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OfxJ_YkeGuEM",
    "outputId": "1217695f-99d0-4c19-c72b-54e1452fcdab"
   },
   "outputs": [],
   "source": [
    "# Create and compile the model\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2D4c7NyZRL4Z"
   },
   "source": [
    "# **Model Checkpint**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hQ_bl0ZWSGhL"
   },
   "outputs": [],
   "source": [
    "model_dir = 'D:\\\\Data\\\\fundus_DenseNet121'\n",
    "\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "checkpoint_path = model_dir + '/cp.ckpt'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 save_best_only=True,  # Save only the best model\n",
    "                                                 monitor=\"val_accuracy\",   # Monitor validation loss\n",
    "                                                 mode=\"max\",           # Save the model when validation loss is minimized\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9qeyTDbukFhz"
   },
   "source": [
    "# **Training Starts Here.....**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5fjxbHYFX6Nv",
    "jp-MarkdownHeadingCollapsed": true,
    "outputId": "66681eae-80c9-4c6f-a3ea-ee734db7f61c"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    x=train_images,\n",
    "    y=train_numeric_labels,\n",
    "    batch_size=8,\n",
    "    steps_per_epoch=50,\n",
    "    epochs=10,\n",
    "    validation_steps=10,\n",
    "    validation_data=(validation_images, validation_numeric_labels),\n",
    "    callbacks=[cp_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SAVE history.....**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the training history\n",
    "initial_epoch = 0  # or the actual initial epoch of the first training session\n",
    "saved_history = {\n",
    "    'loss': history.history['loss'],\n",
    "    'accuracy': history.history['accuracy'],\n",
    "    'val_loss': history.history['val_loss'],\n",
    "    'val_accuracy': history.history['val_accuracy'],\n",
    "    # Add other metrics as needed\n",
    "}\n",
    "np.save(\"D:\\\\Data\\\\fundus_graphs\\\\Dense121_saved_history.npy\", saved_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Loading Saved Model....**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aqfZ6AKRFKrb",
    "outputId": "ea8504fc-ce9a-42b2-e886-b2b8997ac3ed"
   },
   "outputs": [],
   "source": [
    "# Load the latest checkpoint file\n",
    "latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "\n",
    "if latest_checkpoint is not None:\n",
    "    # Create a new model instance\n",
    "    loaded_model = create_model(summary=True)\n",
    "\n",
    "    # Load the previously saved weights and silence the warnings\n",
    "    status = loaded_model.load_weights(latest_checkpoint)\n",
    "    status.expect_partial()  # Ignore unrestored variables\n",
    "else:\n",
    "    print(\"No checkpoint file found in the specified directory.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wFoQgO6EMtrx"
   },
   "source": [
    "# **Load the previous history**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the previous history\n",
    "previous_history = np.load(\"D:\\Data\\\\fundus_graphs\\\\Dense121_saved_history.npy\", allow_pickle=True).item()\n",
    "initial_epoch = len(previous_history['loss'])\n",
    "print(initial_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Again Train the loaded model.....**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6DWSjE3pMqpr"
   },
   "outputs": [],
   "source": [
    "loaded_model.compile(optimizer=Adam(learning_rate=1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VYslEuQ1Ms7n",
    "outputId": "2887d632-a6ff-4482-8146-99350f0ceb82"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = loaded_model.fit(\n",
    "    x=train_images,\n",
    "    initial_epoch=initial_epoch,\n",
    "    y=train_numeric_labels,\n",
    "    batch_size=16,\n",
    "    epochs=50,\n",
    "    validation_data=(validation_images, validation_numeric_labels),\n",
    "    callbacks=[cp_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update and save the training history\n",
    "previous_history['loss'].extend(history.history['loss'])\n",
    "previous_history['accuracy'].extend(history.history['accuracy'])\n",
    "previous_history['val_loss'].extend(history.history['val_loss'])\n",
    "previous_history['val_accuracy'].extend(history.history['val_accuracy'])\n",
    "# Repeat for other metrics as needed\n",
    "\n",
    "np.save(\"D:\\Data\\\\fundus_graphs\\\\Dense121_saved_history.npy\", previous_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "pd.DataFrame(previous_history).to_csv(\"D:\\\\Data\\\\Checkpoints_dense121Epoch.csv\")\n",
    "\n",
    "np.save(\"D:\\Data\\\\fundus_graphs\\\\Dense12_saved_history.npy\", previous_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DY1-RwwiRJwh"
   },
   "source": [
    "# **Accuracy and loss graph of training and validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the saved history\n",
    "previous_history = np.load(\"D:\\Data\\\\fundus_graphs\\\\Dense121_saved_history.npy\", allow_pickle=True).item()\n",
    "\n",
    "# Cap values greater than 5 to 5\n",
    "filtered_history = {\n",
    "    'loss': [],\n",
    "    'accuracy': [],\n",
    "    'val_loss': [],\n",
    "    'val_accuracy': []\n",
    "}\n",
    "\n",
    "threshold_val_loss = 5\n",
    "\n",
    "for epoch in range(len(previous_history['val_loss'])):\n",
    "    # Cap loss and val_loss at 5 if they exceed it\n",
    "    loss_value = min(previous_history['loss'][epoch], threshold_val_loss)\n",
    "    val_loss_value = min(previous_history['val_loss'][epoch], threshold_val_loss)\n",
    "    \n",
    "    filtered_history['loss'].append(loss_value)\n",
    "    filtered_history['accuracy'].append(previous_history['accuracy'][epoch])\n",
    "    filtered_history['val_loss'].append(val_loss_value)\n",
    "    filtered_history['val_accuracy'].append(previous_history['val_accuracy'][epoch])\n",
    "\n",
    "# Save the filtered history\n",
    "np.save(\"D:\\Data\\\\fundus_graphs\\\\Dense121_saved_history.npy\", filtered_history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MLxvuIFzP3wT"
   },
   "source": [
    "# **There will be change in xticks and yticks as per model epochs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 540
    },
    "id": "3uZ9YRoPG86h",
    "outputId": "7a968bb7-faa4-4dff-c5c4-d6d31e339051"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "import numpy as np\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "\n",
    "# Plot Loss\n",
    "train_loss, = plt.plot(previous_history['loss'], label='Train Loss', color='blue')\n",
    "val_loss, = plt.plot(previous_history['val_loss'], label='Validation Loss', color='orange')\n",
    "train_accuracy, = plt.plot(previous_history['accuracy'], label='Train Accuracy',  color='green')\n",
    "val_accuracy, = plt.plot(previous_history['val_accuracy'], label='Validation Accuracy', color='red')\n",
    "# Add a title with specified font properties\n",
    "plt.title('Model Performance during Training', fontdict={'family': 'Serif', 'weight': 'bold', 'size': 12},pad=10)\n",
    "# Set x-axis label with specified font properties\n",
    "plt.xlabel('No. of Epochs', fontdict={'family': 'Serif', 'weight': 'bold', 'size': 12})\n",
    "\n",
    "# Set x-axis ticks font properties\n",
    "#plt.xticks(np.linspace(0, len(history.history['loss']), num=6), fontname='Serif', weight='bold')\n",
    "\n",
    "plt.xticks(np.linspace(0, 60, num=7), fontname='Serif', weight='bold')\n",
    "\n",
    "\n",
    "# Set y-axis ticks font properties\n",
    "plt.yticks(np.linspace(0, 5, num=11), fontname='Serif', weight='bold')\n",
    "\n",
    "# Set the x-axis and y-axis limits\n",
    "#plt.xlim(0, len(history.history['loss']))\n",
    "\n",
    "plt.xlim(0, 50)\n",
    "plt.ylim(0, 5)\n",
    "\n",
    "# Define custom legend lines with desired line properties\n",
    "legend_lines = [\n",
    "    Line2D([0], [0], color='blue', lw=3),          # Train Loss\n",
    "    Line2D([0], [0], color='orange', lw=3),       # Validation Loss\n",
    "    Line2D([0], [0], color='green', lw=3),        # Train Accuracy\n",
    "    Line2D([0], [0], color='red', lw=3)           # Validation Accuracy\n",
    "]\n",
    "\n",
    "# Place legend outside the graph by adjusting bbox_to_anchor and specifying it to be outside the axes\n",
    "plt.legend(legend_lines, ['Train Loss', 'Validation Loss', 'Train Accuracy', 'Validation Accuracy'],\n",
    "           loc='lower center', bbox_to_anchor=(0.5, 1.1), ncol=5,\n",
    "           prop={'family': 'Serif', 'weight': 'bold', 'size': 8}, frameon=False,\n",
    "           handler_map={Line2D: HandlerLine2D(numpoints=5)})\n",
    "\n",
    "# Adjust padding between x-axis label and x-axis ticks\n",
    "plt.gca().xaxis.labelpad = 10  # Change the value as needed to adjust the space\n",
    "\n",
    "# Remove top and right spines\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "# Adjust layout to prevent cropping\n",
    "plt.tight_layout()\n",
    "plt.savefig('D:\\\\Data\\\\fundus_graphs\\\\densenet121_accuracy_graph.pdf')  # Save as pdf format\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b1WeyN2BRkAk"
   },
   "source": [
    "# **Evaluating the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nphfFmbvG8-x",
    "outputId": "cf9f2669-41c5-43ee-e1fc-1f0014a4d281"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "loss, accuracy = loaded_model.evaluate(test_images, test_numeric_labels)\n",
    "\n",
    "# Print the evaluation metrics (loss and accuracy)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9fKz988dRnHp"
   },
   "source": [
    "# **Prediction on Test Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LJOqQUYdHCJb",
    "outputId": "1f52f0bf-015f-4119-ad68-22921bd550b1"
   },
   "outputs": [],
   "source": [
    "# Make predictions on the test dataset\n",
    "predictions = loaded_model.predict(test_images)\n",
    "\n",
    "# Get predicted labels (convert from numeric to string labels using inverse mapping)\n",
    "inverse_label_map = {v: k for k, v in label_map.items()}\n",
    "predicted_labels = [inverse_label_map[np.argmax(pred)] for pred in predictions]\n",
    "# Print test and predicted labels\n",
    "for i in range(len(test_labels)):\n",
    "    print(f\"Test Label: {test_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RKMADnD8RBpn"
   },
   "source": [
    "# **Classification Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jk3zQaFdHCNj",
    "outputId": "69f9c594-decf-4c44-9b0c-3bd6305a5a38"
   },
   "outputs": [],
   "source": [
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(test_labels, predicted_labels, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RiAjJKM6Q9j8"
   },
   "source": [
    "# **Evaluation Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IKW7K34cHGpm",
    "outputId": "9a20e317-807a-4a75-a473-f0946a51d8cf"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss, jaccard_score,roc_auc_score\n",
    "\n",
    "# Assuming predicted_probs contains the probabilities for each class\n",
    "\n",
    "predicted_probs = model.predict(test_images)\n",
    "# Calculate Accuracy\n",
    "accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Calculate Precision, Recall, F1 Score\n",
    "precision = precision_score(test_labels, predicted_labels, average='weighted')\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "recall = recall_score(test_labels, predicted_labels, average='weighted')\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "f1 = f1_score(test_labels, predicted_labels, average='weighted')\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# Calculate Jaccard Score\n",
    "jaccard = jaccard_score(test_labels, predicted_labels, average='weighted')\n",
    "print(f\"Jaccard Score: {jaccard}\")\n",
    "\n",
    "logloss = log_loss(test_numeric_labels, predicted_probs)\n",
    "print(f\"Log Loss: {logloss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B7iMnAKc3H_U"
   },
   "source": [
    "# **ROC AUC Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q6aNu3zdUd0F",
    "outputId": "667b0929-8195-49e0-e8c8-c2c0da8090d6"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode string labels ('A', 'D', 'G', 'N') to numeric labels\n",
    "numeric_test_labels = label_encoder.fit_transform(test_labels)\n",
    "\n",
    "# Calculate ROC AUC score using One-vs-Rest (ovr) strategy\n",
    "roc_auc_ovr = roc_auc_score(numeric_test_labels, predicted_probs, multi_class='ovr')\n",
    "print(f\"ROC AUC Score (One-vs-Rest): {roc_auc_ovr}\")\n",
    "\n",
    "# Calculate ROC AUC score using One-vs-One (ovo) strategy\n",
    "roc_auc_ovo = roc_auc_score(numeric_test_labels, predicted_probs, multi_class='ovo')\n",
    "print(f\"ROC AUC Score (One-vs-One): {roc_auc_ovo}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5bI1tkdMQ6Wq"
   },
   "source": [
    "# **Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "pHkVbDUBHGty",
    "outputId": "49ac4ea1-0532-43a8-9237-64661c29f1ff"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, predicted_labels)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "accuracy_percentage = accuracy * 100\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(5, 4))\n",
    "# Define the custom palette\n",
    "custom_palette = sns.color_palette(\"GnBu\", as_cmap=True)\n",
    "# Define custom font dictionary for title and labels\n",
    "font = {'family': 'Serif', 'weight': 'bold', 'size': 12}\n",
    "font2 = {'family': 'Serif', 'weight': 'bold', 'size': 10}\n",
    "\n",
    "# Create heatmap with annotations and colormap\n",
    "heatmap = sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=custom_palette, vmin = 0,vmax = 35,\n",
    "                      xticklabels=['A', 'D', 'G', 'N'], yticklabels=['A', 'D', 'G', 'N'],\n",
    "                      annot_kws={\"family\": \"Serif\",'weight': 'bold', 'size': 13})\n",
    "\n",
    "# Set x and y labels with the custom font dictionary\n",
    "heatmap.set_xlabel('Predicted Labels', fontdict=font2)\n",
    "heatmap.set_ylabel('Target Labels', fontdict=font2)\n",
    "heatmap.set_title('Fundus Image Classification\\nAccuracy: {:.2f}%'.format(accuracy_percentage),\n",
    "                  fontdict=font, pad=12)\n",
    "\n",
    "# Set font properties for tick labels on both axes\n",
    "heatmap.set_xticklabels(heatmap.get_xticklabels(), fontname='Serif', fontsize=12)\n",
    "heatmap.set_yticklabels(heatmap.get_yticklabels(), fontname='Serif', fontsize=12)\n",
    "\n",
    "# Create a color bar to indicate the scale\n",
    "cbar = heatmap.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=10)\n",
    "# Adjust padding between x-axis label and x-axis ticks\n",
    "plt.gca().xaxis.labelpad = 10  # Change the value as needed to adjust the space\n",
    "plt.tight_layout()\n",
    "plt.savefig('D:\\Data\\\\fundus_graphs\\\\DenseNet121__confusion_matrix.pdf')  # Save as pdf format\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, predicted_labels)\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "accuracy_percentage = accuracy * 100\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(5, 4))\n",
    "# Define the custom palette\n",
    "custom_palette = sns.color_palette(palette='GnBu')# Modify the number based on number of classes in the dataset\n",
    "# Define custom font dictionary for title and labels\n",
    "font = {'family': 'Serif', 'weight': 'bold', 'size': 18}\n",
    "font2 = {'family': 'Serif', 'weight': 'bold', 'size': 15}\n",
    "\n",
    "# Create heatmap with annotations and colormap\n",
    "heatmap = sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=custom_palette,vmin = 0,vmax = 40,\n",
    "                      xticklabels=['A', 'D', 'G', 'N'], yticklabels=['A', 'D', 'G', 'N'],\n",
    "                      annot_kws={\"family\": \"Serif\", 'color':'black','weight': 'bold', 'size': 13})\n",
    "\n",
    "# Set x and y labels with the custom font dictionary\n",
    "heatmap.set_xlabel('Predicted Labels', fontdict=font2)\n",
    "heatmap.set_ylabel('Target Labels', fontdict=font2)\n",
    "heatmap.set_title('Fundus Image Classification\\nAccuracy: {:.2f}%'.format(accuracy_percentage),fontdict=font, pad=12)\n",
    "#heatmap.set_title('Lung and colon Classification', fontdict=font, pad=12)\n",
    "# Set font properties for tick labels on both axes\n",
    "heatmap.set_xticklabels(heatmap.get_xticklabels(), fontname='Serif', fontsize=15)\n",
    "heatmap.set_yticklabels(heatmap.get_yticklabels(), fontname='Serif', fontsize=15)\n",
    "\n",
    "# Create a color bar to indicate the scale\n",
    "cbar = heatmap.collections[0].colorbar\n",
    "cbar.set_label('Count', fontdict=font)\n",
    "cbar.ax.tick_params(labelsize=12)\n",
    "# Adjust padding between x-axis label and x-axis ticks\n",
    "plt.gca().xaxis.labelpad = 10  # Change the value as needed to adjust the space\n",
    "plt.xticks(rotation=0)\n",
    "plt.yticks(rotation=0)\n",
    "# Adjust layout to prevent cropping\n",
    "plt.tight_layout()\n",
    "plt.savefig('D:\\\\Data\\\\DenseNet121__confusion_matrix1.pdf')  # Save as pdf format\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Provided confusion matrix values\n",
    "conf_matrix_values = np.array([[29, 1, 0, 0],\n",
    "[3, 26, 1, 0],\n",
    "[1, 2, 25, 2],\n",
    "[0, 0, 1, 29]])\n",
    "# Calculate accuracy\n",
    "total_samples = np.sum(conf_matrix_values)\n",
    "correct_predictions = np.trace(conf_matrix_values)\n",
    "accuracy = correct_predictions / total_samples * 100\n",
    "accuracy_percentage = accuracy * 100\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(5, 4))\n",
    "# Define the custom palette\n",
    "custom_palette = sns.color_palette(palette='GnBu')# Modify the number based on number of classes in the dataset\n",
    "# Define custom font dictionary for title and labels\n",
    "font = {'family': 'Serif', 'weight': 'bold', 'size': 15}\n",
    "font2 = {'family': 'Serif', 'weight': 'bold', 'size': 15}\n",
    "\n",
    "# Create heatmap with annotations and colormap\n",
    "heatmap = sns.heatmap(conf_matrix_values, annot=True, fmt='d', cmap=custom_palette,vmin = 0,vmax = 35,\n",
    "                      xticklabels=['A', 'D', 'G', 'N'], yticklabels=['A', 'D', 'G', 'N'],\n",
    "                      annot_kws={\"family\": \"Serif\" , 'size': 13})\n",
    "\n",
    "# Set x and y labels with the custom font dictionary\n",
    "heatmap.set_xlabel('Predicted Labels', fontdict=font2)\n",
    "heatmap.set_ylabel('Target Labels', fontdict=font2)\n",
    "heatmap.set_title('Fundus Image Classification\\nAccuracy: {:.2f}%'.format(accuracy),fontdict=font, pad=12)\n",
    "#heatmap.set_title('Lung and colon Classification', fontdict=font, pad=12)\n",
    "# Set font properties for tick labels on both axes\n",
    "heatmap.set_xticklabels(heatmap.get_xticklabels(), fontname='Serif', fontsize=15)\n",
    "heatmap.set_yticklabels(heatmap.get_yticklabels(), fontname='Serif', fontsize=15)\n",
    "\n",
    "# Create a color bar to indicate the scale\n",
    "cbar = heatmap.collections[0].colorbar\n",
    "cbar.set_label('Count', fontdict=font)\n",
    "cbar.ax.tick_params(labelsize=12)\n",
    "# Adjust padding between x-axis label and x-axis ticks\n",
    "plt.gca().xaxis.labelpad = 10  # Change the value as needed to adjust the space\n",
    "plt.xticks(rotation=0)\n",
    "plt.yticks(rotation=0)\n",
    "# Adjust layout to prevent cropping\n",
    "plt.tight_layout()\n",
    "plt.savefig('C:\\\\Users\\\\Mukaffi\\\\Desktop\\\\CM\\\\cm\\\\5.DenseNet121__confusion_matrix.pdf') # Save as pdf format\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LTmgdQ89Y8Cm"
   },
   "source": [
    "# **No. 1 : Explainable AI (GradCAM)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ad3BsMaAY_Wt"
   },
   "source": [
    "* Step 1: Prepare the Model (We've done it already)\n",
    "* Step 2: Load and Preprocess an Image (We'll need an image to visualize the Grad-CAM heatmap)\n",
    "* Step 3: Get the Class Activation Map (CAM) (We'll create a function to generate the Grad-CAM heatmap using the model we've built)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9NpMw3loZK6J"
   },
   "source": [
    "# **Function for displaying Original and GradCAM images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pcFmHiHvU90G"
   },
   "outputs": [],
   "source": [
    "# Function to save and display GradCAM\n",
    "def save_and_display_gradcam(img_path, heatmap, alpha=0.7):\n",
    "    # Load the original image\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (224, 224))  # Resize image to match model input size\n",
    "\n",
    "    # Resize heatmap to match the image dimensions\n",
    "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "\n",
    "    # Rescale heatmap to a range 0-255\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "\n",
    "    # Apply heatmap on the original image\n",
    "    superimposed_img = cv2.addWeighted(heatmap, alpha, img, 1 - alpha, 0)\n",
    "\n",
    "    # Display the GradCAM visualization using Matplotlib\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    plt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('GradCAM', fontdict={'family': 'Serif', 'weight': 'bold', 'size': 12})\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    # Save the figure\n",
    "    plt.savefig('D:\\Data\\\\fundus_graphs\\\\DenseNet_gradcam.pdf')  # Save as pdf format\n",
    "    plt.show()\n",
    "\n",
    "#D:\\Data\\\\fundus_graphs\\\\NASeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6u5jFr8RZQZj"
   },
   "source": [
    "# **GradCAM function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rA_WEeNKZU3F"
   },
   "source": [
    " **Gradient Calculation:** Using these activations, GradCAM computes the gradients of the predicted class's score with respect to the feature maps. These gradients indicate the importance of each feature map in determining the final class prediction.\n",
    "\n",
    "**Global Average Pooling (GAP):** GradCAM takes the gradients and performs Global Average Pooling (GAP) across the spatial dimensions of each feature map. This step generates a weight for each feature map, reflecting its relevance to the predicted class.\n",
    "\n",
    "**Weighted Combination:** GradCAM computes a weighted combination of the feature maps based on their importance weights obtained from GAP. This combination highlights the regions in the feature maps that strongly influence the predicted class.\n",
    "\n",
    "**Heatmap Generation:** The weighted combination produces a heatmap by overlaying these selected regions back onto the input image. The heatmap visually demonstrates which parts of the image are pivotal in the model's decision-making for the predicted class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mnjkshajVE0p"
   },
   "outputs": [],
   "source": [
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "\n",
    "    model.layers[-1].activation = None\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EEMoeKk6ZeAQ"
   },
   "source": [
    "# **Visualization of Grad-Cam**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "XkMMdFBoVGrx",
    "outputId": "06413b84-4dd6-4ef9-c6aa-d241293dae26"
   },
   "outputs": [],
   "source": [
    " # make a prediction and visualize grad-cam\n",
    "def make_prediction_and_visualize_():\n",
    "    img_path = 'D:\\\\Data\\\\fundus\\\\test\\\\Original\\\\106_G.png'\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (224, 224)) #IMG_WIDTH, IMG_HEIGHT\n",
    "    rescaled_img = img/255.0\n",
    "    batch_pred = np.expand_dims(rescaled_img, 0)\n",
    "\n",
    "\n",
    "    last_conv_layer_name = 'conv5_block16_2_conv'\n",
    "\n",
    "    # Generate class activation heatmap\n",
    "    heatmap = make_gradcam_heatmap(batch_pred, loaded_model, last_conv_layer_name)\n",
    "\n",
    "    save_and_display_gradcam(img_path, heatmap)\n",
    "\n",
    "\n",
    "make_prediction_and_visualize_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kc3o68fyZkTj"
   },
   "source": [
    "# **No. 2 : Explainable AI (GradCAM++)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hw8llcdLZmDE"
   },
   "source": [
    "* Step 1: Prepare the Model (We've done it already)\n",
    "* Step 2: Load and Preprocess an Image (We'll need an image to visualize the Grad-CAM++ heatmap)\n",
    "* Step 3: Get the Class Activation Map (CAM) (We'll create a function to generate the Grad-CAM++ heatmap using the model we've built)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fpql0I7SbnhQ"
   },
   "source": [
    "# **Function for displaying Original and GradCAM++ images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hya2TbRZZfuy"
   },
   "outputs": [],
   "source": [
    "# Function to save and display ScoreCAM\n",
    "def save_and_display_gradcam_plusplus(img_path, heatmap, alpha=0.7):\n",
    "    # Load the original image\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (224, 224))  # Resize image to match model input size\n",
    "\n",
    "    # Resize heatmap to match the image dimensions\n",
    "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "\n",
    "    # Rescale heatmap to a range 0-255\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "\n",
    "    # Apply heatmap on the original image\n",
    "    superimposed_img = cv2.addWeighted(heatmap, alpha, img, 1 - alpha, 0)\n",
    "\n",
    "    # Display the GradCAM visualization using Matplotlib\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    plt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('GradCAM++', fontdict={'family': 'Serif', 'weight': 'bold', 'size': 12})\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    # Save the figure\n",
    "    plt.savefig('D:\\Data\\\\fundus_graphs\\\\DenseNet__gradcam_plusplus.pdf')  # Save as pdf format\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rCrxDW3WZ8gO"
   },
   "source": [
    "# **GradCAM++ function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vIWSt123Z_Sa"
   },
   "source": [
    "* **Gradient Computation:** Derive gradients between predicted class and conv layer's output, indicating feature map importance.\n",
    "* **Positive and Negative Gradients:** Split gradients into positive (activating) and negative (inhibiting) parts, signifying influential and counteractive regions.\n",
    "* **Weighting and Aggregation:** Calculate separate importance weights from positive and negative gradients, combining them to determine feature map significance.\n",
    "* **Weighted Sum and Heatmap:** Blend positive and negative weights to generate a weighted sum, utilized for heatmap creation, pinpointing significant regions contributing to the predicted class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0VNgCGh7ZvpK"
   },
   "outputs": [],
   "source": [
    "# Function to generate GradCAM++ heatmap\n",
    "def make_gradcam_plusplus_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    model.layers[-1].activation = None\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_output = preds[:, pred_index]\n",
    "        conv_output = last_conv_layer_output[0]\n",
    "\n",
    "    # Get gradients\n",
    "    grads = tape.gradient(class_output, last_conv_layer_output)\n",
    "    pooled_grads = tf.reduce_mean(grads[0], axis=(0, 1, 2))\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "\n",
    "    # Calculate guided gradients\n",
    "    guided_grads = tf.cast(last_conv_layer_output > 0, 'float32') * grads[0]\n",
    "\n",
    "    # Calculate importance weights\n",
    "    weights = tf.reduce_mean(guided_grads, axis=(0, 1))\n",
    "\n",
    "    # Generate heatmap\n",
    "    heatmap = tf.reduce_sum(tf.multiply(weights, last_conv_layer_output), axis=-1)\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.reduce_max(heatmap)  # Normalize\n",
    "\n",
    "    return heatmap.numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lX8Y8tXPaEKs"
   },
   "source": [
    "# **Visualization of Grad-Cam++**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "4VtFsuXkZy-y",
    "outputId": "2b880bad-911e-43b3-947c-3972fca110e1"
   },
   "outputs": [],
   "source": [
    "# Function to make a prediction and visualize GradCAM++\n",
    "def make_prediction_and_visualize_gradcam_plusplus():\n",
    "    img_path = 'D:\\\\Data\\\\fundus\\\\train\\\\Original\\\\100_A.png'\n",
    "\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (224, 224))  # Resize image to match model input size\n",
    "    rescaled_img = img / 255.0\n",
    "    batch_pred = np.expand_dims(rescaled_img, 0)\n",
    "\n",
    "    last_conv_layer_name = 'conv5_block16_2_conv'\n",
    "\n",
    "    # Generate GradCAM++ heatmap\n",
    "    heatmap = make_gradcam_plusplus_heatmap(batch_pred, loaded_model, last_conv_layer_name)\n",
    "\n",
    "    save_and_display_gradcam_plusplus(img_path, heatmap)\n",
    "\n",
    "make_prediction_and_visualize_gradcam_plusplus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XKL6jPeaI3xS"
   },
   "source": [
    "# **No. 3 : Explainable AI (ScoreCAM)**\n",
    "* Step 1: Prepare the Model (We've done it already)\n",
    "* Step 2: Load and Preprocess an Image (We'll need an image to visualize the Score-CAM heatmap)\n",
    "* Step 3: Get the Class Activation Map (CAM) (We'll create a function to generate the Score-CAM heatmap using the model we've built)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wxLdQdlHH3j6"
   },
   "outputs": [],
   "source": [
    "# Function to save and display ScoreCAM\n",
    "def save_and_display_scorecam(img_path, heatmap, alpha=0.7):\n",
    "    # Load the original image\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (224, 224))  # Resize image to match model input size\n",
    "\n",
    "    # Resize heatmap to match the image dimensions\n",
    "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "\n",
    "    # Rescale heatmap to a range 0-255\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "\n",
    "    # Apply heatmap on the original image\n",
    "    superimposed_img = cv2.addWeighted(heatmap, alpha, img, 1 - alpha, 0)\n",
    "\n",
    "    # Display the GradCAM visualization using Matplotlib\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    plt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('ScoreCAM', fontdict={'family': 'Serif', 'weight': 'bold', 'size': 12})\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    # Save the figure\n",
    "    plt.savefig('D:\\Data\\\\fundus_graphs\\\\DenseNet__scorecam.pdf')  # Save as pdf format\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "32MhpZVIJQ8y"
   },
   "source": [
    "# **ScoreCAM function**\n",
    "* **Gradient Computation:** Score-CAM calculates the gradients of the predicted class score with respect to the output feature maps, just like Grad-CAM. These gradients provide information about the importance of each feature map in the predicted class's activation.\n",
    "* **Guided Gradients:** Instead of considering positive and negative gradients separately, Score-CAM utilizes guided gradients to focus only on positive gradients, i.e., gradients that have a positive influence on the predicted class. This step enhances the saliency of the significant regions.\n",
    "* **Global Average Pooling (GAP):** Score-CAM performs Global Average Pooling (GAP) across the spatial dimensions of the guided gradients to generate importance weights for each feature map, indicating their relevance to the predicted class.\n",
    "* **Score-weighted Activation Map:** The technique computes a score-weighted activation map by multiplying the weights obtained from GAP with the feature maps and summing across channels. This highlights the regions in the feature maps that contribute the most to the predicted class, emphasizing the most discriminative areas in the input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "batQVkPBH3tP"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def make_scorecam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    model.layers[-1].activation = None\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_output = preds[:, pred_index]\n",
    "        conv_output = last_conv_layer_output[0]\n",
    "\n",
    "    # Get the gradients of the predicted class with respect to the output feature map\n",
    "    grads = tape.gradient(class_output, last_conv_layer_output)\n",
    "    guided_grads = tf.cast(grads[0] > 0, 'float32') * grads[0]\n",
    "\n",
    "    # GAP (Global Average Pooling) along the spatial dimensions\n",
    "    weights = tf.reduce_mean(guided_grads, axis=(0, 1))\n",
    "\n",
    "    # Calculate the score-weighted activation map\n",
    "    cam = tf.reduce_sum(tf.multiply(weights, conv_output), axis=-1)\n",
    "    cam = tf.maximum(cam, 0)  # ReLU to ensure non-negativity\n",
    "    cam /= tf.reduce_max(cam)  # Normalize\n",
    "\n",
    "    return cam.numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ilcUnsxJtoU"
   },
   "source": [
    "# **Visualization of ScoreCam**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "3HTEMUWdH31P",
    "outputId": "375f97aa-4c57-4feb-c292-bb356b3a3ee4"
   },
   "outputs": [],
   "source": [
    "# make a prediction and visualize ScoreCAM\n",
    "def make_prediction_and_visualize_scorecam():\n",
    "    img_path = 'D:\\\\Data\\\\fundus\\\\train\\\\Original\\\\100_A.png'\n",
    "\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (224, 224)) #IMG_WIDTH, IMG_HEIGHT\n",
    "    rescaled_img = img/255.0\n",
    "    batch_pred = np.expand_dims(rescaled_img, 0)\n",
    "\n",
    "    last_conv_layer_name = 'conv5_block16_2_conv'\n",
    "\n",
    "    # Generate class activation heatmap\n",
    "    heatmap = make_scorecam_heatmap(batch_pred, loaded_model, last_conv_layer_name)\n",
    "\n",
    "    save_and_display_scorecam(img_path, heatmap)\n",
    "\n",
    "make_prediction_and_visualize_scorecam()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ol-8tq7tKcAf"
   },
   "source": [
    "# **No. 4 : Explainable AI (Faster Score-CAM)**\n",
    "* step 1: Prepare the Model (We've done it already)\n",
    "* Step 2: Load and Preprocess an Image (We'll need an image to visualize the Faster Score-CAM heatmap)\n",
    "* Step 3: Get the Class Activation Map (CAM) (We'll create a function to generate the Faster Score-CAM heatmap using the model we've built)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AlpHLH1QKp2w"
   },
   "source": [
    "# **Function for displaying Original and Faster ScoreCAM images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M0oBHVsWKbEN"
   },
   "outputs": [],
   "source": [
    "# Function to save and display Faster ScoreCAM\n",
    "def save_and_display_faster_scorecam(img_path, heatmap, alpha=0.7):\n",
    "    # Load the original image\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (224, 224))  # Resize image to match model input size\n",
    "\n",
    "    # Resize heatmap to match the image dimensions\n",
    "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "\n",
    "    # Rescale heatmap to a range 0-255\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "\n",
    "    # Apply heatmap on the original image\n",
    "    superimposed_img = cv2.addWeighted(heatmap, alpha, img, 1 - alpha, 0)\n",
    "\n",
    "    # Display the GradCAM visualization using Matplotlib\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    plt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Faster ScoreCAM', fontdict={'family': 'Serif', 'weight': 'bold', 'size': 12})\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    # Save the figure\n",
    "    plt.savefig('D:\\Data\\\\fundus_graphs\\\\DenseNet__faster_scorecam.pdf')  # Save as pdf format\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gFGQRNBHdpJt"
   },
   "source": [
    "# **Faster ScoreCAM function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qvNc_TnPdlfs"
   },
   "source": [
    "* **Gradient Calculation:** Using a GradientTape, it computes the gradients of the predicted class output with respect to the output feature map of the specified last convolutional layer.\n",
    "\n",
    "* **Global Average Pooling (GAP):** The gradients obtained are subjected to Global Average Pooling (GAP) along the spatial dimensions, resulting in weights representing the importance of each feature map in the predicted class's activation.\n",
    "\n",
    "* **Weighted Sum Calculation:** Reshaping the obtained weights and the convolutional output, the function performs matrix multiplication between them, efficiently obtaining a score-weighted activation map that highlights significant regions related to the predicted class.\n",
    "\n",
    "* **Normalization and ReLU:** The resulting score-weighted activation map is normalized and subjected to ReLU (Rectified Linear Unit) activation, ensuring non-negativity and scaling to highlight the most influential regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cCkbuSLUdPJt"
   },
   "outputs": [],
   "source": [
    "def faster_scorecam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    model.layers[-1].activation = None\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_output = preds[:, pred_index]\n",
    "        conv_output = last_conv_layer_output[0]\n",
    "\n",
    "    # Get the gradient of the predicted class with respect to the output feature map\n",
    "    grads = tape.gradient(class_output, last_conv_layer_output)[0]\n",
    "\n",
    "    # Global average pooling (GAP) to compute weights\n",
    "    weights = tf.reduce_mean(grads, axis=(0, 1))\n",
    "\n",
    "    # Reshape the weights to perform matrix multiplication with the convolutional output\n",
    "    weights = tf.reshape(weights, (1, 1, -1))\n",
    "\n",
    "    # Reshape conv_output to match the dimensions for matrix multiplication\n",
    "    conv_output = tf.expand_dims(conv_output, axis=0)\n",
    "    conv_output = tf.expand_dims(conv_output, axis=-1)  # Add a new dimension for matrix multiplication\n",
    "\n",
    "    # Calculate the score-weighted activation map efficiently\n",
    "    cam = tf.matmul(weights, conv_output)\n",
    "    cam = tf.squeeze(cam)\n",
    "    cam = tf.maximum(cam, 0)  # ReLU to ensure non-negativity\n",
    "    cam /= tf.reduce_max(cam)  # Normalize\n",
    "\n",
    "    return cam.numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0I2xd96Adh_q"
   },
   "source": [
    "# **Visualization of faster ScoreCam**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "nC0pd3fEdPN2",
    "outputId": "79f163de-ced4-4a96-d53c-aaac3ca2f094"
   },
   "outputs": [],
   "source": [
    "# make a prediction and visualize Faster ScoreCAM\n",
    "def make_prediction_and_visualize_faster_scorecam():\n",
    "    img_path = 'D:\\\\Data\\\\fundus\\\\train\\\\Original\\\\150_A.png'#'D:\\\\Data\\\\fundus\\\\train\\\\Original/390_G.png'\n",
    "\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (224, 224)) #IMG_WIDTH, IMG_HEIGHT\n",
    "    rescaled_img = img/255.0\n",
    "    batch_pred = np.expand_dims(rescaled_img, 0)\n",
    "\n",
    "    last_conv_layer_name = 'conv5_block16_2_conv'\n",
    "\n",
    "    # Generate class activation heatmap\n",
    "    heatmap = faster_scorecam_heatmap(batch_pred, loaded_model, last_conv_layer_name)\n",
    "\n",
    "    save_and_display_faster_scorecam(img_path, heatmap)\n",
    "\n",
    "make_prediction_and_visualize_faster_scorecam()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MpvJmYOPe_e-"
   },
   "source": [
    "# **No. 5 : Explainable AI (LayerCAM)**\n",
    "\n",
    "* Step 1: Prepare the Model (We've done it already)\n",
    "* Step 2: Load and Preprocess an Image (We'll need an image to visualize the LayerCAM heatmap)\n",
    "* Step 3: Get the Class Activation Map (CAM) (We'll create a function to generate the LayerCAM heatmap using the model we've built)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lnvSkNNZfdBh"
   },
   "source": [
    "# **Function for displaying Original and LayerCAM images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y_NOBIg4dde6"
   },
   "outputs": [],
   "source": [
    "# Function to save and display layercam\n",
    "def save_and_display_layercam(img_path, heatmap, alpha=0.7):\n",
    "    # Load the original image\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (224, 224))  # Resize image to match model input size\n",
    "\n",
    "    # Resize heatmap to match the image dimensions\n",
    "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "\n",
    "    # Rescale heatmap to a range 0-255\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "\n",
    "    # Apply heatmap on the original image\n",
    "    superimposed_img = cv2.addWeighted(heatmap, alpha, img, 1 - alpha, 0)\n",
    "\n",
    "    # Display the GradCAM visualization using Matplotlib\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    plt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('LayerCAM', fontdict={'family': 'Serif', 'weight': 'bold', 'size': 12})\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    # Save the figure\n",
    "    plt.savefig('D:\\Data\\\\fundus_graphs\\\\DenseNet__layercam.pdf')  # Save as pdf format\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05jcCWvGfh8k"
   },
   "source": [
    "# **LayerCAM function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ygusn3cfkvf"
   },
   "source": [
    "* **Gradient Calculation:** Utilize a gradient tape to compute gradients of the predicted class score with respect to the output feature maps obtained from the chosen layer.\n",
    "\n",
    "* **Global Average Pooling (GAP):** Perform Global Average Pooling across the spatial dimensions of the gradients to generate importance weights for each feature map.\n",
    "\n",
    "* **Weight Reshaping:** Reshape the obtained weights to fit the required dimensions for subsequent matrix multiplication.\n",
    "\n",
    "* **Activation Map Computation:** Compute a score-weighted activation map by performing a matrix multiplication between the reshaped weights and the output feature maps from the chosen layer.\n",
    "\n",
    "* **Activation Map Adjustment:** Apply Rectified Linear Unit (ReLU) to ensure non-negativity in the heatmap.\n",
    "\n",
    "* **Normalization:** Normalize the heatmap to ensure that the values fall within a certain range, often between 0 and 1, which aids in visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e8ff6eW1faSr"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def generate_layercam_heatmap(img_array, model, last_conv_layer_name, target_class_index=None):\n",
    "    model.layers[-1].activation = None\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if target_class_index is None:\n",
    "            target_class_index = tf.argmax(preds[0])\n",
    "        class_output = preds[:, target_class_index]\n",
    "        conv_output = last_conv_layer_output[0]\n",
    "\n",
    "    # Calculate gradients of the predicted class with respect to the output feature map\n",
    "    grads = tape.gradient(class_output, last_conv_layer_output)[0]\n",
    "\n",
    "    # Global average pooling (GAP) to compute weights\n",
    "    weights = tf.reduce_mean(grads, axis=(0, 1))\n",
    "\n",
    "    # Reshape the weights to perform matrix multiplication with the convolutional output\n",
    "    weights = tf.reshape(weights, (1, 1, -1))\n",
    "\n",
    "    # Expand dimensions of conv_output for matrix multiplication\n",
    "    conv_output = tf.expand_dims(conv_output, axis=0)\n",
    "    conv_output = tf.expand_dims(conv_output, axis=-1)  # Add a new dimension for matrix multiplication\n",
    "\n",
    "    # Calculate the score-weighted activation map (LayerCAM)\n",
    "    cam = tf.matmul(weights, conv_output)\n",
    "    cam = tf.squeeze(cam)\n",
    "    cam = tf.maximum(cam, 0)  # ReLU to ensure non-negativity\n",
    "    cam /= tf.reduce_max(cam)  # Normalize\n",
    "\n",
    "    return cam.numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_t01JveMfVJX"
   },
   "source": [
    "# **Visualization of LayerCAM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "tseE-1RHddoc",
    "outputId": "604e6332-8b44-4797-eda7-15f4b29f7e21"
   },
   "outputs": [],
   "source": [
    "# make a prediction and visualize layercam\n",
    "def make_prediction_and_visualize_layercam():\n",
    "    img_path = 'D:\\\\Data\\\\fundus\\\\train\\\\Original/100_A.png'\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (224, 224))#IMG_WIDTH, IMG_HEIGHT\n",
    "    rescaled_img = img/255.0\n",
    "    batch_pred = np.expand_dims(rescaled_img, 0)\n",
    "\n",
    "    last_conv_layer_name = 'conv5_block16_2_conv'\n",
    "\n",
    "    # Generate class activation heatmap\n",
    "    heatmap = generate_layercam_heatmap(batch_pred, loaded_model, last_conv_layer_name)\n",
    "\n",
    "    save_and_display_layercam(img_path, heatmap)\n",
    "\n",
    "\n",
    "make_prediction_and_visualize_layercam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
